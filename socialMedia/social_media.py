from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count
from pyspark.ml.feature import (
    Tokenizer,
    StopWordsRemover,
    HashingTF,
    IDF,
    StringIndexer,
    IndexToString
)
from pyspark.ml.classification import LogisticRegression
from pyspark.ml import Pipeline
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator


def main():

    # ==================================================
    # 1Ô∏è‚É£ Start Spark Session
    # ==================================================
    print("\nüöÄ Starting Spark Session...\n")

    spark = SparkSession.builder \
        .appName("Sentiment Analysis - Final Production Version") \
        .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
        .config("spark.hadoop.fs.s3a.aws.credentials.provider",
                "com.amazonaws.auth.DefaultAWSCredentialsProviderChain") \
        .getOrCreate()

    print("‚úÖ Spark session started successfully.\n")

    # ==================================================
    # 2Ô∏è‚É£ Load Dataset
    # ==================================================
    print("üì• Loading dataset from S3...")

    df = spark.read.csv(
        "s3a://social-media-2026/social_media_sentiment_50_records.csv",
        header=True,
        inferSchema=True
    ).dropna()

    total_records = df.count()
    print(f"‚úÖ Dataset loaded successfully. Total records: {total_records}\n")

    # ==================================================
    # 3Ô∏è‚É£ Label Encoding (Safe)
    # ==================================================
    print("üîÑ Encoding sentiment labels...")

    label_indexer = StringIndexer(
        inputCol="sentiment",
        outputCol="label",
        handleInvalid="keep"
    )

    label_model = label_indexer.fit(df)
    df = label_model.transform(df)

    print("‚úÖ Sentiment labels encoded successfully.\n")

    # ==================================================
    # 4Ô∏è‚É£ Train-Test Split
    # ==================================================
    print("üîÄ Splitting dataset into training and testing sets...")

    train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)

    print(f"‚úÖ Data split completed.")
    print(f"   Training records: {train_df.count()}")
    print(f"   Testing records : {test_df.count()}\n")

    # ==================================================
    # 5Ô∏è‚É£ Build ML Pipeline
    # ==================================================
    print("üß† Building Machine Learning pipeline...")

    tokenizer = Tokenizer(inputCol="post_text", outputCol="words")
    remover = StopWordsRemover(inputCol="words", outputCol="filtered_words")
    hashingTF = HashingTF(inputCol="filtered_words", outputCol="rawFeatures", numFeatures=2000)
    idf = IDF(inputCol="rawFeatures", outputCol="features")
    lr = LogisticRegression(featuresCol="features", labelCol="label", maxIter=20)

    pipeline = Pipeline(stages=[
        tokenizer,
        remover,
        hashingTF,
        idf,
        lr
    ])

    print("‚úÖ Pipeline created successfully.\n")

    # ==================================================
    # 6Ô∏è‚É£ Hyperparameter Tuning
    # ==================================================
    print("‚öôÔ∏è Performing hyperparameter tuning with Cross Validation...")

    paramGrid = ParamGridBuilder() \
        .addGrid(hashingTF.numFeatures, [1000, 2000]) \
        .addGrid(lr.regParam, [0.01, 0.1]) \
        .build()

    evaluator = MulticlassClassificationEvaluator(
        labelCol="label",
        predictionCol="prediction",
        metricName="f1"
    )

    cv = CrossValidator(
        estimator=pipeline,
        estimatorParamMaps=paramGrid,
        evaluator=evaluator,
        numFolds=3
    )

    cvModel = cv.fit(train_df)

    print("‚úÖ Model trained successfully using Cross Validation.\n")

    # ==================================================
    # 7Ô∏è‚É£ Generate Predictions
    # ==================================================
    print("üìä Generating predictions on test data...")

    predictions = cvModel.transform(test_df)

    # Convert numeric prediction back to original label
    label_converter = IndexToString(
        inputCol="prediction",
        outputCol="predictedLabel",
        labels=label_model.labels
    )

    predictions = label_converter.transform(predictions)

    print("‚úÖ Predictions generated successfully.\n")

    # ==================================================
    # 8Ô∏è‚É£ Confusion Matrix (Proper Format)
    # ==================================================
    print("üìà Confusion Matrix (Actual vs Predicted)\n")

    confusion = predictions.groupBy(
        col("sentiment").alias("Actual"),
        col("predictedLabel").alias("Predicted")
    ).agg(count("*").alias("Count")) \
     .orderBy("Actual", "Predicted")

    confusion.show(truncate=False)

    print("‚úÖ Confusion matrix generated successfully.\n")

    # ==================================================
    # 9Ô∏è‚É£ Model Evaluation
    # ==================================================
    print("üìè Evaluating model performance...")

    accuracy = MulticlassClassificationEvaluator(
        labelCol="label",
        predictionCol="prediction",
        metricName="accuracy"
    ).evaluate(predictions)

    precision = MulticlassClassificationEvaluator(
        labelCol="label",
        predictionCol="prediction",
        metricName="weightedPrecision"
    ).evaluate(predictions)

    recall = MulticlassClassificationEvaluator(
        labelCol="label",
        predictionCol="prediction",
        metricName="weightedRecall"
    ).evaluate(predictions)

    f1 = MulticlassClassificationEvaluator(
        labelCol="label",
        predictionCol="prediction",
        metricName="f1"
    ).evaluate(predictions)

    print(f"""
üéØ Model Performance
-----------------------
Accuracy  : {accuracy}
Precision : {precision}
Recall    : {recall}
F1 Score  : {f1}
""")

    print("‚úÖ Model evaluation completed successfully.\n")

    # ==================================================
    # üîü Save Predictions to S3
    # ==================================================
    print("üíæ Saving predictions to S3...")

    predictions.select(
        "post_id",
        "post_text",
        "sentiment",
        "predictedLabel"
    ).write.mode("overwrite").csv(
        "s3a://social-media-2026/sentiment_predictions_output/",
        header=True
    )

    print("‚úÖ Predictions saved successfully to S3.\n")

    spark.stop()
    print("üõë Spark session stopped successfully.")


if __name__ == "__main__":
    main()
